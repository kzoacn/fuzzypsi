{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61d6cbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "714a5d11-0a14-4ff0-a919-9216fd02ea72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load from cache\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "#import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "#import insightface\n",
    "from tqdm import tqdm\n",
    "#from insightface.app import FaceAnalysis \n",
    "import pickle\n",
    "import time\n",
    "from leech import Leech\n",
    "import sklearn\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#app = FaceAnalysis(providers=['CPUExecutionProvider'])\n",
    "\n",
    "#app.prepare(ctx_id=0)\n",
    "\n",
    "#feret\n",
    "#def get_name(s):\n",
    "#    return s[:5] \n",
    "\n",
    "#lfw\n",
    "def get_name(s):\n",
    "    return s[:-9] \n",
    "\n",
    "\n",
    "def get_names_vecs(folder):\n",
    "\n",
    "    cache_file = 'embedding_'+folder\n",
    "    if os.path.exists(cache_file):\n",
    "        print('load from cache')\n",
    "        data = pickle.load(open(cache_file,'rb'))\n",
    "        names, vecs = data\n",
    "        return names, vecs \n",
    "    \n",
    "    names = []\n",
    "    vecs = []\n",
    "    name_list=[]\n",
    "    cnt=0\n",
    "    for f in os.listdir(folder):\n",
    "        if f[-3:]=='jpg':\n",
    "            name_list.append(f)\n",
    "\n",
    "    for name in tqdm(name_list):\n",
    "        img = cv2.imread(folder +'/'+ name)\n",
    "        #print(folder+name)\n",
    "        faces = app.get(img)\n",
    "        if len(faces)!=1:\n",
    "            continue\n",
    "        \n",
    "        img_embedding = faces[0].normed_embedding\n",
    "        names.append(get_name(name))\n",
    "        vecs.append(img_embedding)\n",
    "    \n",
    "    data = (names, vecs)\n",
    "    pickle.dump(data,open(cache_file,'wb'))\n",
    "    \n",
    "    return names,vecs\n",
    "\n",
    "names, vecs = get_names_vecs('lfw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "960c3054-63fc-4d87-9f2d-74eb0b0e90a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "random.seed(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b066c201-8415-482b-a401-5de0962dc3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 2**20\n",
    "\n",
    "def round(v):\n",
    "    return [int(x*alpha) for x in v]\n",
    "\n",
    "def padding(v):\n",
    "    v=list(v.copy())\n",
    "    while len(v)%24!=0:\n",
    "        v.append(0)\n",
    "    return np.array(v)\n",
    "    \n",
    "def decode_h(v,t):\n",
    "\n",
    "    \n",
    "    v=padding(v)\n",
    "    \n",
    "    v=round(v)\n",
    "\n",
    "    ds = []\n",
    "    os = []\n",
    "    for i in range(len(v)//24):\n",
    "        sub_v = v[i*24:i*24+24]\n",
    "        decoded = Leech.decode(sub_v,t*alpha)\n",
    "        offset = np.array(sub_v) - np.array(decoded)\n",
    "\n",
    "        ds.append(decoded)\n",
    "        os.append(offset)\n",
    "    return np.concatenate(ds), np.concatenate(os)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab18b425-16ea-4f41-8c6b-f3a230391c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10616/10616 [04:03<00:00, 43.61it/s]\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "def work(vec):\n",
    "    p,o = decode_h(vec ,0.05)\n",
    "    return p,o\n",
    "\n",
    "reset = False\n",
    "\n",
    "if not reset and os.path.exists('decode_cache'):\n",
    "    print('load from cache')\n",
    "    r = pickle.load(open('decode_cache','rb'))\n",
    "else:\n",
    "    with Pool(64) as p:\n",
    "        r = list(tqdm(p.imap(work, vecs), total=len(vecs)))   \n",
    "    pickle.dump(r,open('decode_cache','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "49a853bf-de4a-476d-a079-53fdae79540f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import r_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2871a0f1-6a06-452f-8dd8-9c03c2a3b66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:22<00:00, 22.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0282459457551304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_reg = []\n",
    "for d in tqdm(range(512)):\n",
    "    reg=r_regression(Ps, np.array(Os)[:,d])\n",
    "    all_reg.extend(reg)\n",
    "    \n",
    "print(np.sqrt(np.square(all_reg).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd44951",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
